{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb52261d",
   "metadata": {},
   "source": [
    "[![Labellerr](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/notebook.webp)](https://www.labellerr.com)\n",
    "\n",
    "# **Fine-Tune YOLO for Product Recognition for Price Verification**\n",
    "\n",
    "---\n",
    "\n",
    "[![labellerr](https://img.shields.io/badge/Labellerr-BLOG-black.svg)](https://www.labellerr.com/blog/<BLOG_NAME>)\n",
    "[![Youtube](https://img.shields.io/badge/Labellerr-YouTube-b31b1b.svg)](https://www.youtube.com/@Labellerr)\n",
    "[![Github](https://img.shields.io/badge/Labellerr-GitHub-green.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision)\n",
    "[![Scientific Paper](https://img.shields.io/badge/Official-Paper-blue.svg)](<PAPER LINK>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871a7dab",
   "metadata": {},
   "source": [
    "## **Dataset Creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76de763",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"diyer22/retail-product-checkout-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d5ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import yaml\n",
    "\n",
    "def convert_coco_to_yolo_flat(\n",
    "    json_path: str,\n",
    "    images_dir: str,\n",
    "    output_dir: str,\n",
    "    max_images: int = None,\n",
    "    seed: int = 42,\n",
    "    split: bool = True,\n",
    "    train_ratio: float = 0.8\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert a COCO-like JSON file to flat YOLO detection format with bounding\n",
    "    boxes, optional train/val split, and generate both data.yaml and classes.json.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Load JSON data\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    images      = data['images']\n",
    "    annotations = data['annotations']\n",
    "    categories  = data['categories']\n",
    "\n",
    "    # Build robust category-id → name map\n",
    "    cat_id_to_name = {c['id']: c['name'] for c in categories}\n",
    "    all_ann_ids    = {ann['category_id'] for ann in annotations}\n",
    "    # fallback for any missing\n",
    "    for missing in all_ann_ids - cat_id_to_name.keys():\n",
    "        cat_id_to_name[missing] = f\"class_{missing}\"\n",
    "    sorted_cat_ids = sorted(cat_id_to_name.keys())\n",
    "    # contiguous 0-based mapping\n",
    "    cat_id_map     = {cid: idx for idx, cid in enumerate(sorted_cat_ids)}\n",
    "    class_names    = [cat_id_to_name[cid] for cid in sorted_cat_ids]\n",
    "    num_classes    = len(class_names)\n",
    "\n",
    "    # Group annotations by image\n",
    "    ann_by_image = defaultdict(list)\n",
    "    for ann in annotations:\n",
    "        ann_by_image[ann['image_id']].append(ann)\n",
    "\n",
    "    # Optional max_images sampling evenly across classes\n",
    "    if max_images:\n",
    "        images_by_class = defaultdict(list)\n",
    "        for img in images:\n",
    "            for ann in ann_by_image.get(img['id'], []):\n",
    "                images_by_class[ann['category_id']].append(img)\n",
    "        per_class   = max_images // num_classes\n",
    "        selected_ids = set()\n",
    "        for cid in sorted_cat_ids:\n",
    "            cands = images_by_class.get(cid, [])\n",
    "            if cands:\n",
    "                pick = random.sample(cands, min(per_class, len(cands)))\n",
    "                selected_ids |= {img['id'] for img in pick}\n",
    "        remaining = max_images - len(selected_ids)\n",
    "        if remaining > 0:\n",
    "            others = [img for img in images if img['id'] not in selected_ids]\n",
    "            extra  = random.sample(others, min(remaining, len(others)))\n",
    "            selected_ids |= {img['id'] for img in extra}\n",
    "        images = [img for img in images if img['id'] in selected_ids]\n",
    "\n",
    "    # Split into subsets\n",
    "    if split:\n",
    "        random.shuffle(images)\n",
    "        n_train = int(len(images) * train_ratio)\n",
    "        subsets = {'train': images[:n_train], 'val': images[n_train:]}\n",
    "    else:\n",
    "        subsets = {'all': images}\n",
    "\n",
    "    # Prepare directories\n",
    "    for subset in subsets:\n",
    "        img_out = os.path.join(output_dir, 'images', subset) if split else os.path.join(output_dir, 'images')\n",
    "        lbl_out = os.path.join(output_dir, 'labels', subset) if split else os.path.join(output_dir, 'labels')\n",
    "        os.makedirs(img_out, exist_ok=True)\n",
    "        os.makedirs(lbl_out, exist_ok=True)\n",
    "\n",
    "    # Helper to normalize\n",
    "    def norm(x, m): return x / m\n",
    "\n",
    "    # Process images & write YOLO bbox labels\n",
    "    for subset, imgs in subsets.items():\n",
    "        img_out = os.path.join(output_dir, 'images', subset) if split else os.path.join(output_dir, 'images')\n",
    "        lbl_out = os.path.join(output_dir, 'labels', subset) if split else os.path.join(output_dir, 'labels')\n",
    "        for img in imgs:\n",
    "            src_img = os.path.join(images_dir, img['file_name'])\n",
    "            dst_img = os.path.join(img_out, os.path.basename(img['file_name']))\n",
    "            if not os.path.exists(src_img):\n",
    "                print(f\"Warning: {src_img} does not exist\")\n",
    "                continue\n",
    "            shutil.copy2(src_img, dst_img)\n",
    "\n",
    "            w, h = img['width'], img['height']\n",
    "            lines = []\n",
    "            for ann in ann_by_image.get(img['id'], []):\n",
    "                cid = ann['category_id']\n",
    "                cls_idx = cat_id_map[cid]\n",
    "                bbox = ann.get('bbox', None)\n",
    "                if not bbox or len(bbox) != 4:\n",
    "                    continue\n",
    "                x_min, y_min, bw, bh = bbox\n",
    "                xc = (x_min + bw/2) / w\n",
    "                yc = (y_min + bh/2) / h\n",
    "                lines.append(f\"{cls_idx} {xc:.6f} {yc:.6f} {bw/w:.6f} {bh/h:.6f}\")\n",
    "            # write label file\n",
    "            label_path = os.path.join(lbl_out, os.path.splitext(os.path.basename(img['file_name']))[0] + '.txt')\n",
    "            with open(label_path, 'w', encoding='utf-8') as lf:\n",
    "                lf.write(\"\\n\".join(lines))\n",
    "\n",
    "    # Write data.yaml\n",
    "    data_yaml = {\n",
    "    'path': output_dir,\n",
    "    'train': 'images/train' if split else 'images',\n",
    "    'val':   'images/val'   if split else 'images',\n",
    "    'nc':    num_classes,\n",
    "    # Instead of a list, build a dict of index → class name\n",
    "    'names': {idx: name for idx, name in enumerate(class_names)}\n",
    "}\n",
    "    with open(os.path.join(output_dir, 'data.yaml'), 'w', encoding='utf-8') as yf:\n",
    "        yaml.dump(data_yaml, yf, sort_keys=False)\n",
    "\n",
    "    # Write classes.json\n",
    "    classes_json = {'names': class_names}\n",
    "    with open(os.path.join(output_dir, 'classes.json'), 'w', encoding='utf-8') as jf:\n",
    "        json.dump(classes_json, jf, ensure_ascii=False, indent=2)\n",
    "\n",
    "    total = sum(len(imgs) for imgs in subsets.values())\n",
    "    print(f\"Conversion complete: {total} images\")\n",
    "    print(f\"data.yaml at {os.path.join(output_dir, 'data.yaml')}\")\n",
    "    print(f\"classes.json at {os.path.join(output_dir, 'classes.json')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3363527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_coco_to_yolo_flat(\n",
    "    json_path = r\"archive\\instances_train2019.json\" ,\n",
    "    images_dir = r\"archive\\train2019\",\n",
    "    output_dir = \"yolo_train_format\",\n",
    "    max_images = 5000,\n",
    "    split = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67281156",
   "metadata": {},
   "source": [
    "# **Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44a8d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375eebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"yolo_train_format\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236d821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512836f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8x.pt\")  # Use .pt suffix for weights\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=f\"{dataset_path}/data.yaml\",\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=10,\n",
    "    save_period=10,   # Save checkpoints every 10 epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee58742",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"runs/detect/train/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5123406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(source=\"test_imgz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2390f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "Image.open(\"test_imgz/20180829-10-52-03-1253.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb91962",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(source=\"test_imgz/20180829-10-52-03-1253.jpg\", save= True)\n",
    "\n",
    "print(results[0].boxes)  # Print class \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e22963",
   "metadata": {},
   "source": [
    "# **CHECKOUT SYSTEM CREATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecd9aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# Your existing mappings\n",
    "SUPERCLASS_MAP = {\n",
    "    'puffed_food': list(range(0, 12)),\n",
    "    'dried_fruit': list(range(12, 21)),\n",
    "    'dried_food': list(range(21, 30)),\n",
    "    'instant_drink': list(range(30, 41)),\n",
    "    'instant_noodles': list(range(41, 53)),\n",
    "    'dessert': list(range(53, 70)),\n",
    "    'drink':     list(range(70, 78)) + list(range(80, 87)),\n",
    "    'alcohol':   list(range(78, 80)) + list(range(87, 96)),\n",
    "    'milk':      list(range(96, 107)),\n",
    "    'canned_food': list(range(107, 121)),\n",
    "    'chocolate': list(range(121, 133)),\n",
    "    'gum':       list(range(133, 141)),\n",
    "    'candy':     list(range(141, 151)),\n",
    "    'seasoner':  list(range(151, 163)),\n",
    "    'personal_hygiene': list(range(163, 173)),\n",
    "    'tissue':    list(range(173, 193)),\n",
    "    'stationery':list(range(193, 200)),\n",
    "}\n",
    "\n",
    "# Invert mapping: class index → superclass name\n",
    "INDEX_TO_SUPER = {}\n",
    "for super_name, idx_list in SUPERCLASS_MAP.items():\n",
    "    for idx in idx_list:\n",
    "        INDEX_TO_SUPER[idx] = super_name\n",
    "\n",
    "# Assign a unique color to each superclass (BGR format for OpenCV)\n",
    "random.seed(42)  # For consistent colors\n",
    "SUPERCLASS_COLORS = {\n",
    "    super_name: tuple(random.choices(range(50, 256), k=3))\n",
    "    for super_name in SUPERCLASS_MAP\n",
    "}\n",
    "\n",
    "INDEX_TO_SUPER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e614f86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_and_count_superclasses(image, results, confidence_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Annotate YOLO detections with superclass colors and return superclass counts.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image (numpy array)\n",
    "        results: YOLO results object from model inference\n",
    "        confidence_threshold: Minimum confidence to consider detection\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (annotated_image, superclass_counts)\n",
    "            - annotated_image: Image with bounding boxes and labels\n",
    "            - superclass_counts: Dictionary with superclass names as keys and counts as values\n",
    "    \"\"\"\n",
    "    annotated_image = image.copy()\n",
    "    superclass_counts = defaultdict(int)\n",
    "    \n",
    "    # Get detection data from YOLO results\n",
    "    if hasattr(results, '__len__') and len(results) > 0:\n",
    "        r = results[0]  # First image results\n",
    "        \n",
    "        if r.boxes is not None and len(r.boxes) > 0:\n",
    "            # Extract detection data\n",
    "            boxes = r.boxes.xyxy.cpu().numpy()  # x1, y1, x2, y2\n",
    "            confidences = r.boxes.conf.cpu().numpy()\n",
    "            class_ids = r.boxes.cls.cpu().numpy().astype(int)\n",
    "            \n",
    "            for i, (box, conf, class_id) in enumerate(zip(boxes, confidences, class_ids)):\n",
    "                if conf < confidence_threshold:\n",
    "                    continue\n",
    "                \n",
    "                # Get superclass for this class_id\n",
    "                superclass = INDEX_TO_SUPER.get(class_id, 'unknown')\n",
    "                if superclass == 'unknown':\n",
    "                    continue\n",
    "                \n",
    "                # Count this detection\n",
    "                superclass_counts[superclass] += 1\n",
    "                \n",
    "                # Get color for this superclass\n",
    "                color = SUPERCLASS_COLORS.get(superclass, (128, 128, 128))\n",
    "                \n",
    "                # Draw bounding box\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                cv2.rectangle(annotated_image, (x1, y1), (x2, y2), color, 2)\n",
    "                \n",
    "                # Prepare label text\n",
    "                original_class_name = r.names[class_id] if hasattr(r, 'names') else f\"class_{class_id}\"\n",
    "                label = f\"{superclass}: {original_class_name} ({conf:.2f})\"\n",
    "                \n",
    "                # Calculate text size and background\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                font_scale = 0.6\n",
    "                thickness = 1\n",
    "                (text_width, text_height), baseline = cv2.getTextSize(label, font, font_scale, thickness)\n",
    "                \n",
    "                # Draw background rectangle for text\n",
    "                cv2.rectangle(annotated_image, \n",
    "                            (x1, y1 - text_height - 10), \n",
    "                            (x1 + text_width, y1), \n",
    "                            color, -1)\n",
    "                \n",
    "                # Draw text\n",
    "                cv2.putText(annotated_image, label, \n",
    "                          (x1, y1 - 5), \n",
    "                          font, font_scale, \n",
    "                          (255, 255, 255), thickness)\n",
    "    \n",
    "    return annotated_image, dict(superclass_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f400a146",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"test_imgz/20180829-10-52-03-1253.jpg\")\n",
    "result_img, count = annotate_and_count_superclasses(image, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f172a0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0227bf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "plt.axis('off')\n",
    "plt.imshow(result_img[..., ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dcf3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
    "    results = model.predict(source=image_path)\n",
    "    result_img, count = annotate_and_count_superclasses(image, results)\n",
    "    \n",
    "    print(f\"Detected superclasses: {count}\")\n",
    "    \n",
    "    plt.figure(figsize=(16, 16))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(result_img[..., ::-1])\n",
    "    plt.show()\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1ce5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = pipeline(\"test_imgz/20180829-10-52-03-1253.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb01b66",
   "metadata": {},
   "source": [
    "## **Adding Total Price Counting Feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b072b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUPERCLASS_PRICE = {\n",
    "    'puffed_food': 100,\n",
    "    'dried_fruit': 90,\n",
    "    'dried_food': 80,\n",
    "    'instant_drink': 70,\n",
    "    'instant_noodles': 55,\n",
    "    'dessert': 60,\n",
    "    'drink': 50,\n",
    "    'alcohol': 100,\n",
    "    'milk': 40,\n",
    "    'canned_food': 30,\n",
    "    'chocolate': 2,\n",
    "    'gum': 1,\n",
    "    'candy': 5,\n",
    "    'seasoner': 25,\n",
    "    'personal_hygiene': 20,\n",
    "    'tissue': 15,\n",
    "    'stationery': 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de038b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_price(counts: dict):\n",
    "    \"\"\"\n",
    "    Calculate and print total price based on detection counts and superclass prices\n",
    "    \n",
    "    Args:\n",
    "        counts: Dictionary with superclass names as keys and detection counts as values\n",
    "        prices: Dictionary with superclass names as keys and prices as values\n",
    "    \n",
    "    Returns:\n",
    "        float: Total calculated price\n",
    "    \"\"\"\n",
    "    prices = SUPERCLASS_PRICE\n",
    "    total_price = 0\n",
    "    print(\"Price Breakdown:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for superclass, count in counts.items():\n",
    "        if superclass in prices:\n",
    "            item_price = prices[superclass]\n",
    "            subtotal = item_price * count\n",
    "            total_price += subtotal\n",
    "            \n",
    "            print(f\"{superclass:15} | {count:2d} × {item_price:3d} = {subtotal:4d}\")\n",
    "        else:\n",
    "            print(f\"{superclass:15} | {count:2d} × ??? = ???  (Price not found)\")\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"{'TOTAL':15} |            = {total_price:4.0f}\")\n",
    "    \n",
    "    return total_price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c542a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = calculate_total_price(count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb09149",
   "metadata": {},
   "source": [
    "## **Final Checkout Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4092ad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkout(image_path):\n",
    "    \"\"\"\n",
    "    Perform checkout by calculating total price based on detected items in the image.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the input image for detection\n",
    "    \n",
    "    Returns:\n",
    "        float: Total price of detected items\n",
    "    \"\"\"\n",
    "    counts = pipeline(image_path)\n",
    "    total_price = calculate_total_price(counts)\n",
    "    print(f\"Total price for items in {image_path}: ${total_price}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189878ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkout(\"test_imgz/20180829-10-52-03-1253.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07179d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(\"test_imgz/20180927-09-49-23-1945.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f443aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkout(\"test_imgz/20180927-09-49-23-1945.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune-yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
