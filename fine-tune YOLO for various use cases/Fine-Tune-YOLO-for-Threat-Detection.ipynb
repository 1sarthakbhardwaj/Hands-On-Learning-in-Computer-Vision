{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0511fe5",
   "metadata": {},
   "source": [
    "[![Labellerr](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/notebook.webp)](https://www.labellerr.com)\n",
    "\n",
    "# **Fine-Tune YOLO for Threat Detection**\n",
    "\n",
    "---\n",
    "\n",
    "[![labellerr](https://img.shields.io/badge/Labellerr-BLOG-black.svg)](https://www.labellerr.com/blog/<BLOG_NAME>)\n",
    "[![Youtube](https://img.shields.io/badge/Labellerr-YouTube-b31b1b.svg)](https://www.youtube.com/@Labellerr)\n",
    "[![Github](https://img.shields.io/badge/Labellerr-GitHub-green.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision)\n",
    "[![Scientific Paper](https://img.shields.io/badge/Official-Paper-blue.svg)](<PAPER LINK>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf519a8",
   "metadata": {},
   "source": [
    "### **Create Dataset and Annotation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfa4c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect various images of threats like guns from the internet.\n",
    "# Annotate the images using a tool like Labellerr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3b626e",
   "metadata": {},
   "source": [
    "### **Convert COCO JSON Annotation to YOLO format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eb4a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Labellerr/yolo_finetune_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92a1393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolo_finetune_utils.coco_yolo_converter.seg_converter import coco_to_yolo_converter\n",
    "\n",
    "result = coco_to_yolo_converter(\n",
    "            json_path='./annotation.json',\n",
    "            images_dir='./dataset',\n",
    "            output_dir='yolo_format'\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640e2d65",
   "metadata": {},
   "source": [
    "### **Train YOLO11 Model on a Custom Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9466b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4cbbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=train data=\"path/to/dataset.yaml\" model=\"yolo11x.pt\" epochs=200 imgsz=640 batch=20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d98e26e",
   "metadata": {},
   "source": [
    "### **Inferencing Fine-Tune YOLO model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e6e32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the YOLO11 model\n",
    "model = YOLO('./runs/detect/train3/weights/best.pt', task=\"detect\")\n",
    "\n",
    "# Open video capture\n",
    "cap = cv2.VideoCapture(\"./assests/wep2.mp4\")\n",
    "\n",
    "# Define video writer to save output\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "output = cv2.VideoWriter('output.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run inference on the frame\n",
    "    results = model(frame)\n",
    "    \n",
    "    # Process each detection\n",
    "    for result in results[0].boxes:\n",
    "        # Get box coordinates\n",
    "        x1, y1, x2, y2 = map(int, result.xyxy[0])\n",
    "        \n",
    "        # Get confidence and class\n",
    "        confidence = float(result.conf[0])\n",
    "        class_id = int(result.cls[0])\n",
    "        class_name = \" GUN \"\n",
    "        \n",
    "        if confidence > 0.3:  # Confidence threshold\n",
    "            # Create translucent overlay\n",
    "            overlay = frame.copy()\n",
    "            cv2.rectangle(overlay, (x1, y1), (x2, y2), (0, 0, 255), -1)  # Solid red rectangle\n",
    "            alpha = 0.4  # Transparency factor\n",
    "            cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)\n",
    "\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 1)\n",
    "\n",
    "            # Add label\n",
    "            label = f'{class_name} {confidence *100:.2f}%'\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "    # Write the frame with annotation to output video\n",
    "    output.write(frame)\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "output.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune-yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
