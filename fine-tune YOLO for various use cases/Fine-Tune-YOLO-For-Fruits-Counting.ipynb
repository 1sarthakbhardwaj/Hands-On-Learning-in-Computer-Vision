{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "134b78e1",
   "metadata": {},
   "source": [
    "[![Labellerr](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/notebook.webp)](https://www.labellerr.com)\n",
    "\n",
    "# **Fine-Tune-YOLO-For-Fruits-Counting**\n",
    "\n",
    "---\n",
    "\n",
    "[![labellerr](https://img.shields.io/badge/Labellerr-BLOG-black.svg)](https://www.labellerr.com/blog/<BLOG_NAME>)\n",
    "[![Youtube](https://img.shields.io/badge/Labellerr-YouTube-b31b1b.svg)](https://www.youtube.com/@Labellerr)\n",
    "[![Github](https://img.shields.io/badge/Labellerr-GitHub-green.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision)\n",
    "[![Scientific Paper](https://img.shields.io/badge/Official-Paper-blue.svg)](<PAPER LINK>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81efa6ca",
   "metadata": {},
   "source": [
    "### **Dataset Creation and Annotation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e777a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Labellerr/yolo_finetune_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dddfeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolo_finetune_utils.frame_extractor import extract_random_frames\n",
    "\n",
    "extract_random_frames(paths=[r\"assests\\2.mp4\"], \n",
    "                      out_dir='dataset', \n",
    "                      total_images=20,\n",
    "                      seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac62125",
   "metadata": {},
   "source": [
    "### **Converting COCO-JSON to YOLO format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421dca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolo_finetune_utils.coco_yolo_converter.seg_converter import coco_to_yolo_converter\n",
    "\n",
    "coco_to_yolo_converter(json_path=\"annotation.json\", images_dir=\"dataset\", output_dir=\"yolo_format\", seed=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8e3bf9",
   "metadata": {},
   "source": [
    "### **Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d0f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04222696",
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=segment mode=train data=\"./yolo_format/data.yaml\" model=\"yolo11m-seg.pt\" epochs=250 imgsz=640 batch=30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165797bc",
   "metadata": {},
   "source": [
    "### **Tracking using Custom Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be19e5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=segment mode=track tracker=botsort.yaml model=\"./runs/segment/train/weights/best.pt\" conf=0.2 source=\"./assests/2.mp4\" save=True show_labels=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed461a9b",
   "metadata": {},
   "source": [
    "### **Drawing Counter Line**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23b88ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = r'assests\\2.mp4'  # ‚Üê VIDEO PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dcabd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(f\"‚ùå Error: Cannot open video file: {video_path}\")\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 100)  # Set to frame number 100\n",
    "ret, frame = cap.read()\n",
    "cap.release()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a374e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(f\"‚ùå Error: Cannot open video file: {video_path}\")\n",
    "else:\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "print(f\"Width: {width}, Height: {height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d08354",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = (1500,0), (1500,1080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899064d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_point, end_point = line\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(f\"‚ùå Error: Cannot open video file: {video_path}\")\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 100)  # Set to frame number 100\n",
    "ret, frame = cap.read()\n",
    "cap.release()\n",
    "\n",
    "if ret:\n",
    "    \n",
    "    cv2.line(frame, start_point, end_point, (255, 120, 255), 10)\n",
    "    \n",
    "    TEXT = \"COUNTING LINE\"\n",
    "    cv2.putText(frame, TEXT, (1510, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 120, 255), 10)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364f878f",
   "metadata": {},
   "source": [
    "### **Fruits Counting Logic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40c27e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# =============================================================================\n",
    "# GLOBAL VARIABLES\n",
    "# =============================================================================\n",
    "product_counter = 0\n",
    "perform_segmentation = False  # Set to True to enable segmentation visualization\n",
    "counting_line = (line)  # line coordinates\n",
    "video_path = \"assests/2.mp4\"\n",
    "output_video_path = \"output5.mp4\"\n",
    "model_path = \"./runs/segment/train/weights/best.pt\"  # Trained segmentation model\n",
    "model_confidence = 0.9  # Confidence threshold for YOLO model\n",
    "\n",
    "# =============================================================================\n",
    "# FUNCTIONS\n",
    "# =============================================================================\n",
    "def load_yolo_model(model_path):\n",
    "    \"\"\"Load YOLO model\"\"\"\n",
    "    global model\n",
    "    try:\n",
    "        print(f\"Loading YOLO segmentation model: {model_path}\")\n",
    "        model = YOLO(model_path)\n",
    "        print(\"YOLO model loaded successfully\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading YOLO model: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def line_intersection(p1, p2, p3, p4):\n",
    "    \"\"\"Check if line p1-p2 intersects with line p3-p4\"\"\"\n",
    "    def ccw(A, B, C):\n",
    "        return (C[1] - A[1]) * (B[0] - A[0]) > (B[1] - A[1]) * (C[0] - A[0])\n",
    "    return ccw(p1, p3, p4) != ccw(p2, p3, p4) and ccw(p1, p2, p3) != ccw(p1, p2, p4)\n",
    "\n",
    "\n",
    "def check_line_crossing(prev_pos, curr_pos, obj_id):\n",
    "    \"\"\"Check if object crosses the counting line\"\"\"\n",
    "    global product_counter, counted_objects\n",
    "    if line_intersection(prev_pos, curr_pos, counting_line[0], counting_line[1]):\n",
    "        if obj_id not in counted_objects:  # Only count once per object\n",
    "            counted_objects.add(obj_id)\n",
    "            product_counter += 1\n",
    "            print(f\"üéØ Object {obj_id} crossed the line! Total count: {product_counter}\")\n",
    "\n",
    "\n",
    "def process_video():\n",
    "    \"\"\"Main function to process video\"\"\"\n",
    "    global product_counter, counted_objects\n",
    "    \n",
    "    print(f\"Starting Product Counter\")\n",
    "    print(f\"Input: {video_path}\")\n",
    "    print(f\"Output: {output_video_path}\")\n",
    "    print(f\"Model: {model_path}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Load model\n",
    "    if not load_yolo_model(model_path):\n",
    "        return False\n",
    "\n",
    "    # Open input video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"‚ùå Cannot open video: {video_path}\")\n",
    "        return False\n",
    "\n",
    "    # Get video properties\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    print(f\"Video: {width}x{height} @ {fps}fps, {total_frames} frames\")\n",
    "\n",
    "    # Create output video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    # Reset counter and tracking\n",
    "    product_counter = 0\n",
    "    counted_objects = set()  # Track which objects have been counted\n",
    "    track_history = {}  # {id: (prev_center)}\n",
    "\n",
    "    frame_count = 0\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    print(\"Processing...\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        # Run YOLO segmentation + tracking\n",
    "        results = model.track(frame, conf=model_confidence, tracker=\"botsort.yaml\", persist=True, verbose=False)\n",
    "\n",
    "        if results and results[0].boxes.id is not None:\n",
    "            # Draw segmentation masks with color coding\n",
    "            if results[0].masks is not None:\n",
    "                masks = results[0].masks.xy  # list of polygons\n",
    "                boxes = results[0].boxes\n",
    "                \n",
    "                if perform_segmentation == True:\n",
    "                    for i, seg in enumerate(masks):\n",
    "                        if i < len(boxes):\n",
    "                            obj_id = int(boxes[i].id[0].cpu().numpy())\n",
    "                            \n",
    "                            # Color based on counting status\n",
    "                            if obj_id in counted_objects:\n",
    "                                # Yellow translucent for counted objects\n",
    "                                color = (0, 255, 255)  # BGR format: Yellow\n",
    "                                fill_color = (0, 255, 255, 100)  # Yellow with alpha\n",
    "                            else:\n",
    "                                # Purple translucent for uncounted objects\n",
    "                                color = (255, 0, 255)  # BGR format: Purple/Magenta\n",
    "                                fill_color = (255, 0, 255, 100)  # Purple with alpha\n",
    "                            \n",
    "                            pts = np.array(seg, dtype=np.int32)\n",
    "                            \n",
    "                            # Create overlay for translucent fill\n",
    "                            overlay = frame.copy()\n",
    "                            cv2.fillPoly(overlay, [pts], color)\n",
    "                            cv2.addWeighted(overlay, 0.3, frame, 0.7, 0, frame)\n",
    "                            \n",
    "                            # Draw outline\n",
    "                            cv2.polylines(frame, [pts], True, color, 2)\n",
    "\n",
    "            # Draw tracked objects\n",
    "            for box in results[0].boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                obj_id = int(box.id[0].cpu().numpy())\n",
    "                cls_id = int(box.cls[0].cpu().numpy())\n",
    "                conf = float(box.conf[0].cpu().numpy())\n",
    "\n",
    "                # Object center\n",
    "                center_x = int((x1 + x2) / 2)\n",
    "                center_y = int((y1 + y2) / 2)\n",
    "                center = (center_x, center_y)\n",
    "\n",
    "                # Check line crossing\n",
    "                if obj_id in track_history:\n",
    "                    prev_center = track_history[obj_id]\n",
    "                    check_line_crossing(prev_center, center, obj_id)\n",
    "                track_history[obj_id] = center\n",
    "\n",
    "                # Draw bounding box with color coding\n",
    "                box_color = (0, 255, 255) if obj_id in counted_objects else (255, 0, 255)\n",
    "                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), box_color, 2)\n",
    "                cv2.putText(frame, f\"ID:{obj_id}\", (int(x1), int(y1) - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "                cv2.circle(frame, center, 5, (0, 0, 255), -1)\n",
    "\n",
    "        # Draw counting line\n",
    "        cv2.line(frame, counting_line[0], counting_line[1], (0, 255, 0), 10)\n",
    "        cv2.putText(frame, \"COUNTING LINE\",\n",
    "                    ((counting_line[0][0] + counting_line[1][0]) // 2 + 20,\n",
    "                     (counting_line[0][1] + counting_line[1][1]) // 2),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 10)\n",
    "\n",
    "        # Draw counter\n",
    "        cv2.rectangle(frame, (10, 10), (200, 60), (0, 0, 0), -1)\n",
    "        cv2.putText(frame, f\"COUNT: {product_counter}\", (20, 45),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "        # Show progress every 10%\n",
    "        if total_frames > 0 and frame_count % max(1, total_frames // 10) == 0:\n",
    "            progress = (frame_count / total_frames) * 100\n",
    "            print(f\"üìà {progress:.0f}% - Frame {frame_count}/{total_frames} - Count: {product_counter}\")\n",
    "\n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    processing_time = end_time - start_time\n",
    "\n",
    "    # Results\n",
    "    print(\"=\"*50)\n",
    "    print(\"Processing completed!\")\n",
    "    print(f\"Total count: {product_counter}\")\n",
    "    print(f\"Processing time: {processing_time}\")\n",
    "    print(f\"Output saved: {output_video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c676ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_video()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
