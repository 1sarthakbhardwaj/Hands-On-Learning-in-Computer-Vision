{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e94e21",
   "metadata": {},
   "source": [
    "[![Labellerr](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/notebook.webp)](https://www.labellerr.com)\n",
    "\n",
    "# Mask2Former\n",
    "\n",
    "---\n",
    "\n",
    "[![labellerr](https://img.shields.io/badge/Labellerr-BLOG-black.svg)](https://www.labellerr.com/blog/<BLOG_NAME>)\n",
    "[![Youtube](https://img.shields.io/badge/Labellerr-YouTube-b31b1b.svg)](https://www.youtube.com/@Labellerr)\n",
    "[![Github](https://img.shields.io/badge/Labellerr-GitHub-green.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision)\n",
    "[![Scientific Paper](https://img.shields.io/badge/Official-Paper-blue.svg)](<PAPER LINK>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16f3bc9",
   "metadata": {},
   "source": [
    "# About Mask2Former\n",
    "\n",
    "Mask2Former is a universal image segmentation architecture developed by Meta AI Research in 2022. It is designed to handle all major segmentation tasks-semantic, instance, and panoptic segmentation-with a single, unified framework. This model builds on the MaskFormer architecture, introducing key innovations to improve both performance and efficiency.\n",
    "\n",
    "![Labellerr](https://storage.googleapis.com/labellerr-cdn/%200%20Mask2Former/main.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e43becd",
   "metadata": {},
   "outputs": [],
   "source": [
    "! uv pip install transformers torch scipy matplotlib opencv-python pillow scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63aa1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from skimage.measure import regionprops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d501a357",
   "metadata": {},
   "source": [
    "# Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca889d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_segmentation(results, image, model, alpha=0.4):\n",
    "    \"\"\"\n",
    "    Visualizes segmentation results with object names and color lines\n",
    "    on the right edge of the image. The alpha parameter controls mask opacity.\n",
    "    \"\"\"\n",
    "    segmentation = results['segmentation'].numpy()\n",
    "    segments_info = results['segments_info']\n",
    "    height, width = segmentation.shape\n",
    "    color_mask = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Assign random color to each instance\n",
    "    instance_colors = {\n",
    "        segment['id']: np.random.randint(0, 255, size=3)\n",
    "        for segment in segments_info\n",
    "    }\n",
    "\n",
    "    for segment in segments_info:\n",
    "        mask = segmentation == segment['id']\n",
    "        color_mask[mask] = instance_colors[segment['id']]\n",
    "\n",
    "    # Overlay mask on image with alpha blending\n",
    "    image_np = np.array(image).astype(np.uint8)\n",
    "    overlay = (1 - alpha) * image_np + alpha * color_mask\n",
    "    overlay = overlay.astype(np.uint8)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(overlay)\n",
    "    ax = plt.gca()\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Draw color lines and names on the right edge\n",
    "    line_height = 25\n",
    "    spacing = 10\n",
    "    y0 = spacing\n",
    "    for segment in segments_info:\n",
    "        label_name = model.config.id2label[segment['label_id']]\n",
    "        color = instance_colors[segment['id']] / 255\n",
    "\n",
    "        # Draw color line\n",
    "        rect = mpatches.Rectangle(\n",
    "            (width - 30, y0), 20, line_height,\n",
    "            linewidth=0, edgecolor=None, facecolor=color, alpha=1.0, transform=ax.transData, clip_on=False\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Draw label text\n",
    "        ax.text(\n",
    "            width - 35, y0 + line_height / 2,\n",
    "            f\"{label_name} ({segment['score']:.2f})\",\n",
    "            va='center', ha='right', fontsize=11,\n",
    "            color='white' if np.mean(color) < 0.5 else 'black',\n",
    "            bbox=dict(facecolor=(0, 0, 0, 0.2), edgecolor='none', boxstyle='round,pad=0.2')\n",
    "        )\n",
    "        y0 += line_height + spacing\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def draw_binary_mask(results, model):\n",
    "    segmentation = results['segmentation']\n",
    "    segments_info = results['segments_info']\n",
    "    seg_np = segmentation.numpy() if hasattr(segmentation, 'numpy') else np.array(segmentation)\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(seg_np)\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # Map segment id to label id\n",
    "    segment_to_label = {segment['id']: segment['label_id'] for segment in segments_info}\n",
    "\n",
    "    # For each segment, find centroid and plot label\n",
    "    for segment in segments_info:\n",
    "        segment_id = segment['id']\n",
    "        label_id = segment['label_id']\n",
    "        label_name = model.config.id2label[label_id]\n",
    "        mask = (seg_np == segment_id)\n",
    "        props = regionprops(mask.astype(np.uint8))\n",
    "        if props:\n",
    "            y, x = props[0].centroid\n",
    "            ax.text(\n",
    "                x, y, label_name,\n",
    "                color='white', fontsize=8, weight='bold',\n",
    "                ha='center', va='center',\n",
    "                bbox=dict(facecolor='black', alpha=0.5, boxstyle='round,pad=0.2')\n",
    "            )\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def visualize_semantic_map(predicted_map, original_image, model, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Visualizes the semantic segmentation map over the original image.\n",
    "    The alpha parameter controls the transparency of the mask (0=transparent, 1=opaque).\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Generate a random color palette\n",
    "    color_palette = np.random.randint(0, 255, size=(len(model.config.id2label), 3))\n",
    "    color_seg = np.zeros((predicted_map.shape[0], predicted_map.shape[1], 3), dtype=np.uint8)\n",
    "    \n",
    "    for label in torch.unique(predicted_map):\n",
    "        color_seg[predicted_map == label] = color_palette[label]\n",
    "    \n",
    "    # Blend the original image and the color mask using the alpha parameter\n",
    "    img = np.array(original_image) * (1 - alpha) + color_seg * alpha\n",
    "    img = img.astype(np.uint8)\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec845b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://i.pinimg.com/736x/1e/de/d8/1eded82fbcfc288327d9f12795dbab7b.jpg\"\n",
    "# url = \"https://i.pinimg.com/736x/da/c6/12/dac612292f2cb04c82d6b41fdb6a1c6a.jpg\"\n",
    "# url = \"https://i.pinimg.com/736x/4e/9f/7b/4e9f7ba5e373204ce3a0737494ab76c3.jpg\"\n",
    "# url = \"https://i.pinimg.com/736x/9a/67/16/9a6716e63ff0afb1cee5931ade66e388.jpg\"\n",
    "# url = \"https://i.pinimg.com/736x/59/e6/ae/59e6ae53b2bcee83dd57e4e3b1ce7d7c.jpg\"\n",
    "# url = \"https://i.pinimg.com/736x/07/18/53/07185391756d6eef0ef73ea9d0b56ef9.jpg\"\n",
    "url = \"https://i.pinimg.com/736x/16/4f/21/164f213bb141fa9957926531d4056ceb.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0b184b",
   "metadata": {},
   "source": [
    "# SEMANTIC SEGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562fa8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_semantic_segmentation(image_path):\n",
    "    \"\"\"Performs semantic segmentation using Cityscapes-trained model\"\"\"\n",
    "    # Load model and processor\n",
    "    checkpoint= \"facebook/mask2former-swin-large-ade-semantic\"\n",
    "    processor = AutoImageProcessor.from_pretrained(checkpoint)\n",
    "    model = Mask2FormerForUniversalSegmentation.from_pretrained(checkpoint)\n",
    "    \n",
    "    # Load image\n",
    "    if image_path.startswith('http'):\n",
    "        image = Image.open(requests.get(image_path, stream=True).raw)\n",
    "    else:\n",
    "        image = Image.open(image_path)\n",
    "    \n",
    "    # Process and predict\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Post-process\n",
    "    predicted_map = processor.post_process_semantic_segmentation(outputs, target_sizes=[image.size[::-1]])[0]\n",
    "    \n",
    "    return predicted_map, image, model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561d07d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic segmentation\n",
    "# url = \"https://cdn-media.huggingface.co/Inference-API/Sample-results-on-the-Cityscapes-dataset-The-above-images-show-how-our-method-can-handle.png\"\n",
    "# url = \"https://i.pinimg.com/736x/cb/b1/3f/cbb13f0a3ef98d8e180a19ff8bd7f43a.jpg\"\n",
    "predicted_map, image, model = run_semantic_segmentation(url)\n",
    "\n",
    "visualize_semantic_map(predicted_map, image, model, alpha=0.6)\n",
    "visualize_semantic_map(predicted_map, image, model, alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23321a67",
   "metadata": {},
   "source": [
    "# INSTANCE SEGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe50b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_instance_segmentation(image_path):\n",
    "    \"\"\"\n",
    "    Runs instance segmentation on an image and visualizes the results.\n",
    "    \"\"\"\n",
    "    # Load model and processor\n",
    "    checkpoint = \"facebook/mask2former-swin-large-coco-instance\"\n",
    "    processor = AutoImageProcessor.from_pretrained(checkpoint)\n",
    "    model = Mask2FormerForUniversalSegmentation.from_pretrained(checkpoint)\n",
    "\n",
    "    # Load image\n",
    "    if image_path.startswith('http'):\n",
    "        image = Image.open(requests.get(image_path, stream=True).raw).convert(\"RGB\")\n",
    "    else:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    # Preprocess and inference\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Post-process\n",
    "    results = processor.post_process_instance_segmentation(\n",
    "        outputs, target_sizes=[image.size[::-1]]\n",
    "    )[0]\n",
    "\n",
    "    # Visualize\n",
    "    return results, image, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1ba623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance segmentation\n",
    "# url = \"https://i.pinimg.com/736x/cb/b1/3f/cbb13f0a3ef98d8e180a19ff8bd7f43a.jpg\"\n",
    "# url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "instance_results, image, model = run_instance_segmentation(url)\n",
    "draw_binary_mask(instance_results, model)\n",
    "visualize_segmentation(instance_results, image, model, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d725cf7e",
   "metadata": {},
   "source": [
    "# PANOPTIC SEGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468bd833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_panoptic_segmentation(image_path):\n",
    "    \"\"\"Performs panoptic segmentation using COCO-trained model\"\"\"\n",
    "    # Load model and processor\n",
    "    checkpoint = \"facebook/mask2former-swin-base-coco-panoptic\"\n",
    "    processor = AutoImageProcessor.from_pretrained(checkpoint)\n",
    "    model = Mask2FormerForUniversalSegmentation.from_pretrained(checkpoint)\n",
    "    \n",
    "    # Load image\n",
    "    if image_path.startswith('http'):\n",
    "        image = Image.open(requests.get(image_path, stream=True).raw)\n",
    "    else:\n",
    "        image = Image.open(image_path)\n",
    "    \n",
    "    # Process and predict\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Post-process\n",
    "    results = processor.post_process_panoptic_segmentation(outputs, target_sizes=[image.size[::-1]])[0]\n",
    "    \n",
    "    return results, image, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c755c8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panoptic segmentation\n",
    "# url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "# url = \"https://i.pinimg.com/736x/cb/b1/3f/cbb13f0a3ef98d8e180a19ff8bd7f43a.jpg\"\n",
    "panoptic_results, image, model = run_panoptic_segmentation(url)\n",
    "# Visualize\n",
    "draw_binary_mask(panoptic_results, model)\n",
    "visualize_segmentation(panoptic_results, image, model, alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f0be4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
